{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.MNIST('data', train=True, transform=torchvision.transforms.ToTensor(), download=True)\n",
    "dataloader = DataLoader(mnist, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "images, labels = next(iter(dataloader))\n",
    "\n",
    "plt.imshow(images[0, 0], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedConvolution(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, mask_center = False):\n",
    "        super(GatedConvolution, self).__init__()\n",
    "\n",
    "        mask = torch.ones(kernel_size, kernel_size)\n",
    "        mask[kernel_size // 2, kernel_size // 2 + int(mask_center == False):] = 0\n",
    "        mask[kernel_size // 2 + 1:] = 0\n",
    "        self.register_buffer('mask', mask)\n",
    "        \n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=kernel_size // 2, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # set the focus point of the convolution to 0\n",
    "        self.conv.weight.data *= self.mask\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "    def __init__(self, hidden_size=32, hidden_count=15):\n",
    "        super(PixelCNN, self).__init__()\n",
    "        \n",
    "        self.cnn = nn.Sequential(\n",
    "            GatedConvolution(1, hidden_size, kernel_size=7, mask_center=True),\n",
    "            *([GatedConvolution(hidden_size, hidden_size, kernel_size=3)]*hidden_count),\n",
    "            nn.Conv2d(hidden_size, 256, kernel_size=1, bias=False),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.cnn(x).permute(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PixelCNN(\n",
       "  (cnn): Sequential(\n",
       "    (0): GatedConvolution(\n",
       "      (conv): Conv2d(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): GatedConvolution(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): GatedConvolution(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): GatedConvolution(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): GatedConvolution(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): GatedConvolution(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): GatedConvolution(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): GatedConvolution(\n",
       "      (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pixelCNN = PixelCNN(64, 7)\n",
    "pixelCNN.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 (500/3750) - loss 3.518610071897507\n",
      "Epoch 1 (1000/3750) - loss 2.297934065282345\n",
      "Epoch 1 (1500/3750) - loss 1.823931870063146\n",
      "Epoch 1 (2000/3750) - loss 1.5791080386936664\n",
      "Epoch 1 (2500/3750) - loss 1.4304657124996185\n",
      "Epoch 1 (3000/3750) - loss 1.329449253420035\n",
      "Epoch 1 (3500/3750) - loss 1.2558438196693147\n",
      "Epoch 1 (3750/3750) - loss 1.2260171822865804\n",
      "Epoch 2 (500/3750) - loss 0.8034354287385941\n",
      "Epoch 2 (1000/3750) - loss 0.8015150263309478\n",
      "Epoch 2 (1500/3750) - loss 0.800840026696523\n",
      "Epoch 2 (2000/3750) - loss 0.7999077412188054\n",
      "Epoch 2 (2500/3750) - loss 0.7985126483917236\n",
      "Epoch 2 (3000/3750) - loss 0.7971583453615506\n",
      "Epoch 2 (3500/3750) - loss 0.795571159686361\n",
      "Epoch 2 (3750/3750) - loss 0.7950209711869558\n",
      "Epoch 3 (500/3750) - loss 0.7835225384235383\n",
      "Epoch 3 (1000/3750) - loss 0.7820484685301781\n",
      "Epoch 3 (1500/3750) - loss 0.7809921594063441\n",
      "Epoch 3 (2000/3750) - loss 0.7815805571079254\n",
      "Epoch 3 (2500/3750) - loss 0.7806578437805176\n",
      "Epoch 3 (3000/3750) - loss 0.7794840499957403\n",
      "Epoch 3 (3500/3750) - loss 0.7790241908005305\n",
      "Epoch 3 (3750/3750) - loss 0.778732910044988\n",
      "Epoch 4 (500/3750) - loss 0.7760686005353927\n",
      "Epoch 4 (1000/3750) - loss 0.7736248915791512\n",
      "Epoch 4 (1500/3750) - loss 0.7730393823782603\n",
      "Epoch 4 (2000/3750) - loss 0.7725802608132363\n",
      "Epoch 4 (2500/3750) - loss 0.7713568784236908\n",
      "Epoch 4 (3000/3750) - loss 0.7707316598892212\n",
      "Epoch 4 (3500/3750) - loss 0.7707938695805413\n",
      "Epoch 4 (3750/3750) - loss 0.7707238676548004\n",
      "Epoch 5 (500/3750) - loss 0.7678042590618134\n",
      "Epoch 5 (1000/3750) - loss 0.7680454064011574\n",
      "Epoch 5 (1500/3750) - loss 0.7677325385411581\n",
      "Epoch 5 (2000/3750) - loss 0.766791980266571\n",
      "Epoch 5 (2500/3750) - loss 0.7667632609844208\n",
      "Epoch 5 (3000/3750) - loss 0.7659734602173169\n",
      "Epoch 5 (3500/3750) - loss 0.7661499668530055\n",
      "Epoch 5 (3750/3750) - loss 0.7657714172999064\n",
      "Epoch 6 (500/3750) - loss 0.763813600897789\n",
      "Epoch 6 (1000/3750) - loss 0.7646220854520798\n",
      "Epoch 6 (1500/3750) - loss 0.7641590052843094\n",
      "Epoch 6 (2000/3750) - loss 0.7639452088773251\n",
      "Epoch 6 (2500/3750) - loss 0.763062665963173\n",
      "Epoch 6 (3000/3750) - loss 0.7630053224960963\n",
      "Epoch 6 (3500/3750) - loss 0.7624382635354996\n",
      "Epoch 6 (3750/3750) - loss 0.7622520262877146\n",
      "Epoch 7 (500/3750) - loss 0.7596410715579986\n",
      "Epoch 7 (1000/3750) - loss 0.7592292007803917\n",
      "Epoch 7 (1500/3750) - loss 0.7602619382143021\n",
      "Epoch 7 (2000/3750) - loss 0.7596915042996406\n",
      "Epoch 7 (2500/3750) - loss 0.7602702331066131\n",
      "Epoch 7 (3000/3750) - loss 0.7599711321393648\n",
      "Epoch 7 (3500/3750) - loss 0.7595166370868683\n",
      "Epoch 7 (3750/3750) - loss 0.7593757637023926\n"
     ]
    }
   ],
   "source": [
    "epochs = 20\n",
    "print_every = 500\n",
    "\n",
    "optimizer = optim.Adam(pixelCNN.parameters(), lr=0.0002)\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.tensor([1, 10]).cuda())\n",
    "\n",
    "for e in range(1, epochs+1):\n",
    "    total_loss = 0\n",
    "    pixelCNN.train()\n",
    "    for batch, (images, labels) in enumerate(dataloader):\n",
    "        images = images.cuda()\n",
    "        target = (images * 255).long().view(-1)\n",
    "        \n",
    "        pred = pixelCNN(images)\n",
    "        pred = pred.contiguous().view(-1, 256)\n",
    "        \n",
    "        loss = criterion(pred, target)\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (batch+1) % print_every == 0 or (batch+1) == len(dataloader):\n",
    "            print(f\"Epoch {e} ({batch+1}/{len(dataloader)}) - loss {total_loss/(batch+1)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check generation\n",
    "images, labels = next(iter(dataloader))\n",
    "pixelCNN.eval()\n",
    "with torch.no_grad():\n",
    "    pred = pixelCNN(images.cuda())\n",
    "    pred = pred.softmax(-1).argmax(-1)\n",
    "\n",
    "plt.imshow(pred[0].cpu(), cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "num_samples = 1\n",
    "sample = torch.zeros(num_samples, 1, 28, 28).cuda()\n",
    "temperature = 0.7\n",
    "\n",
    "pixelCNN.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(28):\n",
    "        for j in range(28):\n",
    "            pred = pixelCNN(sample)\n",
    "            pred = (pred[:, i, j]/temperature).softmax(dim=-1)\n",
    "            \n",
    "            pixel = torch.multinomial(pred, 1).float() / 255.\n",
    "            sample[:, :, i, j] = pixel\n",
    "            \n",
    "plt.imshow(sample[0,0].cpu(), cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
